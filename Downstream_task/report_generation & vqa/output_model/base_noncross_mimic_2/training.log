02/25/2021 10:09:04 - INFO - __main__ -   device: cuda n_gpu: 2, distributed training: False, 16-bits training: False
02/25/2021 10:09:05 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/jhmoon/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
02/25/2021 10:09:08 - INFO - pytorch_pretrained_bert.model -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./output_model/base_noncross_mimic_2/.pretrained_model_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
02/25/2021 10:09:08 - INFO - pytorch_pretrained_bert.model -   extracting archive file ./output_model/base_noncross_mimic_2/.pretrained_model_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpn60qm4_5
02/25/2021 10:09:13 - INFO - pytorch_pretrained_bert.model -   Model config {
  "_name_or_path": "/home/hg_lee/cxr-bert/output/Base_sc_baseline/20210203_003450/7",
  "architectures": [
    "CXRBERT"
  ],
  "attention_probs_dropout_prob": 0.1,
  "fp32_embedding": false,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label_smoothing": null,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "relax_projection": 0,
  "task_idx": 3,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

02/25/2021 10:09:21 - INFO - pytorch_pretrained_bert.model -   Weights of BertForPreTrainingLossMask not initialized from pretrained model: ['bert.txt_embeddings.word_embeddings.weight', 'bert.txt_embeddings.position_embeddings.weight', 'bert.txt_embeddings.token_type_embeddings.weight', 'bert.txt_embeddings.LayerNorm.weight', 'bert.txt_embeddings.LayerNorm.bias', 'bert.img_embeddings.img_embeddings.weight', 'bert.img_embeddings.img_embeddings.bias', 'bert.img_embeddings.position_embeddings.weight', 'bert.img_embeddings.token_type_embeddings.weight', 'bert.img_embeddings.word_embeddings.weight', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias', 'bert.img_encoder.model.0.weight', 'bert.img_encoder.model.1.weight', 'bert.img_encoder.model.1.bias', 'bert.img_encoder.model.1.running_mean', 'bert.img_encoder.model.1.running_var', 'bert.img_encoder.model.4.0.conv1.weight', 'bert.img_encoder.model.4.0.bn1.weight', 'bert.img_encoder.model.4.0.bn1.bias', 'bert.img_encoder.model.4.0.bn1.running_mean', 'bert.img_encoder.model.4.0.bn1.running_var', 'bert.img_encoder.model.4.0.conv2.weight', 'bert.img_encoder.model.4.0.bn2.weight', 'bert.img_encoder.model.4.0.bn2.bias', 'bert.img_encoder.model.4.0.bn2.running_mean', 'bert.img_encoder.model.4.0.bn2.running_var', 'bert.img_encoder.model.4.0.conv3.weight', 'bert.img_encoder.model.4.0.bn3.weight', 'bert.img_encoder.model.4.0.bn3.bias', 'bert.img_encoder.model.4.0.bn3.running_mean', 'bert.img_encoder.model.4.0.bn3.running_var', 'bert.img_encoder.model.4.0.downsample.0.weight', 'bert.img_encoder.model.4.0.downsample.1.weight', 'bert.img_encoder.model.4.0.downsample.1.bias', 'bert.img_encoder.model.4.0.downsample.1.running_mean', 'bert.img_encoder.model.4.0.downsample.1.running_var', 'bert.img_encoder.model.4.1.conv1.weight', 'bert.img_encoder.model.4.1.bn1.weight', 'bert.img_encoder.model.4.1.bn1.bias', 'bert.img_encoder.model.4.1.bn1.running_mean', 'bert.img_encoder.model.4.1.bn1.running_var', 'bert.img_encoder.model.4.1.conv2.weight', 'bert.img_encoder.model.4.1.bn2.weight', 'bert.img_encoder.model.4.1.bn2.bias', 'bert.img_encoder.model.4.1.bn2.running_mean', 'bert.img_encoder.model.4.1.bn2.running_var', 'bert.img_encoder.model.4.1.conv3.weight', 'bert.img_encoder.model.4.1.bn3.weight', 'bert.img_encoder.model.4.1.bn3.bias', 'bert.img_encoder.model.4.1.bn3.running_mean', 'bert.img_encoder.model.4.1.bn3.running_var', 'bert.img_encoder.model.4.2.conv1.weight', 'bert.img_encoder.model.4.2.bn1.weight', 'bert.img_encoder.model.4.2.bn1.bias', 'bert.img_encoder.model.4.2.bn1.running_mean', 'bert.img_encoder.model.4.2.bn1.running_var', 'bert.img_encoder.model.4.2.conv2.weight', 'bert.img_encoder.model.4.2.bn2.weight', 'bert.img_encoder.model.4.2.bn2.bias', 'bert.img_encoder.model.4.2.bn2.running_mean', 'bert.img_encoder.model.4.2.bn2.running_var', 'bert.img_encoder.model.4.2.conv3.weight', 'bert.img_encoder.model.4.2.bn3.weight', 'bert.img_encoder.model.4.2.bn3.bias', 'bert.img_encoder.model.4.2.bn3.running_mean', 'bert.img_encoder.model.4.2.bn3.running_var', 'bert.img_encoder.model.5.0.conv1.weight', 'bert.img_encoder.model.5.0.bn1.weight', 'bert.img_encoder.model.5.0.bn1.bias', 'bert.img_encoder.model.5.0.bn1.running_mean', 'bert.img_encoder.model.5.0.bn1.running_var', 'bert.img_encoder.model.5.0.conv2.weight', 'bert.img_encoder.model.5.0.bn2.weight', 'bert.img_encoder.model.5.0.bn2.bias', 'bert.img_encoder.model.5.0.bn2.running_mean', 'bert.img_encoder.model.5.0.bn2.running_var', 'bert.img_encoder.model.5.0.conv3.weight', 'bert.img_encoder.model.5.0.bn3.weight', 'bert.img_encoder.model.5.0.bn3.bias', 'bert.img_encoder.model.5.0.bn3.running_mean', 'bert.img_encoder.model.5.0.bn3.running_var', 'bert.img_encoder.model.5.0.downsample.0.weight', 'bert.img_encoder.model.5.0.downsample.1.weight', 'bert.img_encoder.model.5.0.downsample.1.bias', 'bert.img_encoder.model.5.0.downsample.1.running_mean', 'bert.img_encoder.model.5.0.downsample.1.running_var', 'bert.img_encoder.model.5.1.conv1.weight', 'bert.img_encoder.model.5.1.bn1.weight', 'bert.img_encoder.model.5.1.bn1.bias', 'bert.img_encoder.model.5.1.bn1.running_mean', 'bert.img_encoder.model.5.1.bn1.running_var', 'bert.img_encoder.model.5.1.conv2.weight', 'bert.img_encoder.model.5.1.bn2.weight', 'bert.img_encoder.model.5.1.bn2.bias', 'bert.img_encoder.model.5.1.bn2.running_mean', 'bert.img_encoder.model.5.1.bn2.running_var', 'bert.img_encoder.model.5.1.conv3.weight', 'bert.img_encoder.model.5.1.bn3.weight', 'bert.img_encoder.model.5.1.bn3.bias', 'bert.img_encoder.model.5.1.bn3.running_mean', 'bert.img_encoder.model.5.1.bn3.running_var', 'bert.img_encoder.model.5.2.conv1.weight', 'bert.img_encoder.model.5.2.bn1.weight', 'bert.img_encoder.model.5.2.bn1.bias', 'bert.img_encoder.model.5.2.bn1.running_mean', 'bert.img_encoder.model.5.2.bn1.running_var', 'bert.img_encoder.model.5.2.conv2.weight', 'bert.img_encoder.model.5.2.bn2.weight', 'bert.img_encoder.model.5.2.bn2.bias', 'bert.img_encoder.model.5.2.bn2.running_mean', 'bert.img_encoder.model.5.2.bn2.running_var', 'bert.img_encoder.model.5.2.conv3.weight', 'bert.img_encoder.model.5.2.bn3.weight', 'bert.img_encoder.model.5.2.bn3.bias', 'bert.img_encoder.model.5.2.bn3.running_mean', 'bert.img_encoder.model.5.2.bn3.running_var', 'bert.img_encoder.model.5.3.conv1.weight', 'bert.img_encoder.model.5.3.bn1.weight', 'bert.img_encoder.model.5.3.bn1.bias', 'bert.img_encoder.model.5.3.bn1.running_mean', 'bert.img_encoder.model.5.3.bn1.running_var', 'bert.img_encoder.model.5.3.conv2.weight', 'bert.img_encoder.model.5.3.bn2.weight', 'bert.img_encoder.model.5.3.bn2.bias', 'bert.img_encoder.model.5.3.bn2.running_mean', 'bert.img_encoder.model.5.3.bn2.running_var', 'bert.img_encoder.model.5.3.conv3.weight', 'bert.img_encoder.model.5.3.bn3.weight', 'bert.img_encoder.model.5.3.bn3.bias', 'bert.img_encoder.model.5.3.bn3.running_mean', 'bert.img_encoder.model.5.3.bn3.running_var', 'bert.img_encoder.model.6.0.conv1.weight', 'bert.img_encoder.model.6.0.bn1.weight', 'bert.img_encoder.model.6.0.bn1.bias', 'bert.img_encoder.model.6.0.bn1.running_mean', 'bert.img_encoder.model.6.0.bn1.running_var', 'bert.img_encoder.model.6.0.conv2.weight', 'bert.img_encoder.model.6.0.bn2.weight', 'bert.img_encoder.model.6.0.bn2.bias', 'bert.img_encoder.model.6.0.bn2.running_mean', 'bert.img_encoder.model.6.0.bn2.running_var', 'bert.img_encoder.model.6.0.conv3.weight', 'bert.img_encoder.model.6.0.bn3.weight', 'bert.img_encoder.model.6.0.bn3.bias', 'bert.img_encoder.model.6.0.bn3.running_mean', 'bert.img_encoder.model.6.0.bn3.running_var', 'bert.img_encoder.model.6.0.downsample.0.weight', 'bert.img_encoder.model.6.0.downsample.1.weight', 'bert.img_encoder.model.6.0.downsample.1.bias', 'bert.img_encoder.model.6.0.downsample.1.running_mean', 'bert.img_encoder.model.6.0.downsample.1.running_var', 'bert.img_encoder.model.6.1.conv1.weight', 'bert.img_encoder.model.6.1.bn1.weight', 'bert.img_encoder.model.6.1.bn1.bias', 'bert.img_encoder.model.6.1.bn1.running_mean', 'bert.img_encoder.model.6.1.bn1.running_var', 'bert.img_encoder.model.6.1.conv2.weight', 'bert.img_encoder.model.6.1.bn2.weight', 'bert.img_encoder.model.6.1.bn2.bias', 'bert.img_encoder.model.6.1.bn2.running_mean', 'bert.img_encoder.model.6.1.bn2.running_var', 'bert.img_encoder.model.6.1.conv3.weight', 'bert.img_encoder.model.6.1.bn3.weight', 'bert.img_encoder.model.6.1.bn3.bias', 'bert.img_encoder.model.6.1.bn3.running_mean', 'bert.img_encoder.model.6.1.bn3.running_var', 'bert.img_encoder.model.6.2.conv1.weight', 'bert.img_encoder.model.6.2.bn1.weight', 'bert.img_encoder.model.6.2.bn1.bias', 'bert.img_encoder.model.6.2.bn1.running_mean', 'bert.img_encoder.model.6.2.bn1.running_var', 'bert.img_encoder.model.6.2.conv2.weight', 'bert.img_encoder.model.6.2.bn2.weight', 'bert.img_encoder.model.6.2.bn2.bias', 'bert.img_encoder.model.6.2.bn2.running_mean', 'bert.img_encoder.model.6.2.bn2.running_var', 'bert.img_encoder.model.6.2.conv3.weight', 'bert.img_encoder.model.6.2.bn3.weight', 'bert.img_encoder.model.6.2.bn3.bias', 'bert.img_encoder.model.6.2.bn3.running_mean', 'bert.img_encoder.model.6.2.bn3.running_var', 'bert.img_encoder.model.6.3.conv1.weight', 'bert.img_encoder.model.6.3.bn1.weight', 'bert.img_encoder.model.6.3.bn1.bias', 'bert.img_encoder.model.6.3.bn1.running_mean', 'bert.img_encoder.model.6.3.bn1.running_var', 'bert.img_encoder.model.6.3.conv2.weight', 'bert.img_encoder.model.6.3.bn2.weight', 'bert.img_encoder.model.6.3.bn2.bias', 'bert.img_encoder.model.6.3.bn2.running_mean', 'bert.img_encoder.model.6.3.bn2.running_var', 'bert.img_encoder.model.6.3.conv3.weight', 'bert.img_encoder.model.6.3.bn3.weight', 'bert.img_encoder.model.6.3.bn3.bias', 'bert.img_encoder.model.6.3.bn3.running_mean', 'bert.img_encoder.model.6.3.bn3.running_var', 'bert.img_encoder.model.6.4.conv1.weight', 'bert.img_encoder.model.6.4.bn1.weight', 'bert.img_encoder.model.6.4.bn1.bias', 'bert.img_encoder.model.6.4.bn1.running_mean', 'bert.img_encoder.model.6.4.bn1.running_var', 'bert.img_encoder.model.6.4.conv2.weight', 'bert.img_encoder.model.6.4.bn2.weight', 'bert.img_encoder.model.6.4.bn2.bias', 'bert.img_encoder.model.6.4.bn2.running_mean', 'bert.img_encoder.model.6.4.bn2.running_var', 'bert.img_encoder.model.6.4.conv3.weight', 'bert.img_encoder.model.6.4.bn3.weight', 'bert.img_encoder.model.6.4.bn3.bias', 'bert.img_encoder.model.6.4.bn3.running_mean', 'bert.img_encoder.model.6.4.bn3.running_var', 'bert.img_encoder.model.6.5.conv1.weight', 'bert.img_encoder.model.6.5.bn1.weight', 'bert.img_encoder.model.6.5.bn1.bias', 'bert.img_encoder.model.6.5.bn1.running_mean', 'bert.img_encoder.model.6.5.bn1.running_var', 'bert.img_encoder.model.6.5.conv2.weight', 'bert.img_encoder.model.6.5.bn2.weight', 'bert.img_encoder.model.6.5.bn2.bias', 'bert.img_encoder.model.6.5.bn2.running_mean', 'bert.img_encoder.model.6.5.bn2.running_var', 'bert.img_encoder.model.6.5.conv3.weight', 'bert.img_encoder.model.6.5.bn3.weight', 'bert.img_encoder.model.6.5.bn3.bias', 'bert.img_encoder.model.6.5.bn3.running_mean', 'bert.img_encoder.model.6.5.bn3.running_var', 'bert.img_encoder.model.7.0.conv1.weight', 'bert.img_encoder.model.7.0.bn1.weight', 'bert.img_encoder.model.7.0.bn1.bias', 'bert.img_encoder.model.7.0.bn1.running_mean', 'bert.img_encoder.model.7.0.bn1.running_var', 'bert.img_encoder.model.7.0.conv2.weight', 'bert.img_encoder.model.7.0.bn2.weight', 'bert.img_encoder.model.7.0.bn2.bias', 'bert.img_encoder.model.7.0.bn2.running_mean', 'bert.img_encoder.model.7.0.bn2.running_var', 'bert.img_encoder.model.7.0.conv3.weight', 'bert.img_encoder.model.7.0.bn3.weight', 'bert.img_encoder.model.7.0.bn3.bias', 'bert.img_encoder.model.7.0.bn3.running_mean', 'bert.img_encoder.model.7.0.bn3.running_var', 'bert.img_encoder.model.7.0.downsample.0.weight', 'bert.img_encoder.model.7.0.downsample.1.weight', 'bert.img_encoder.model.7.0.downsample.1.bias', 'bert.img_encoder.model.7.0.downsample.1.running_mean', 'bert.img_encoder.model.7.0.downsample.1.running_var', 'bert.img_encoder.model.7.1.conv1.weight', 'bert.img_encoder.model.7.1.bn1.weight', 'bert.img_encoder.model.7.1.bn1.bias', 'bert.img_encoder.model.7.1.bn1.running_mean', 'bert.img_encoder.model.7.1.bn1.running_var', 'bert.img_encoder.model.7.1.conv2.weight', 'bert.img_encoder.model.7.1.bn2.weight', 'bert.img_encoder.model.7.1.bn2.bias', 'bert.img_encoder.model.7.1.bn2.running_mean', 'bert.img_encoder.model.7.1.bn2.running_var', 'bert.img_encoder.model.7.1.conv3.weight', 'bert.img_encoder.model.7.1.bn3.weight', 'bert.img_encoder.model.7.1.bn3.bias', 'bert.img_encoder.model.7.1.bn3.running_mean', 'bert.img_encoder.model.7.1.bn3.running_var', 'bert.img_encoder.model.7.2.conv1.weight', 'bert.img_encoder.model.7.2.bn1.weight', 'bert.img_encoder.model.7.2.bn1.bias', 'bert.img_encoder.model.7.2.bn1.running_mean', 'bert.img_encoder.model.7.2.bn1.running_var', 'bert.img_encoder.model.7.2.conv2.weight', 'bert.img_encoder.model.7.2.bn2.weight', 'bert.img_encoder.model.7.2.bn2.bias', 'bert.img_encoder.model.7.2.bn2.running_mean', 'bert.img_encoder.model.7.2.bn2.running_var', 'bert.img_encoder.model.7.2.conv3.weight', 'bert.img_encoder.model.7.2.bn3.weight', 'bert.img_encoder.model.7.2.bn3.bias', 'bert.img_encoder.model.7.2.bn3.running_mean', 'bert.img_encoder.model.7.2.bn3.running_var', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'bert.cls.predictions.bias', 'bert.cls.predictions.transform.dense.weight', 'bert.cls.predictions.transform.dense.bias', 'bert.cls.predictions.transform.LayerNorm.weight', 'bert.cls.predictions.transform.LayerNorm.bias', 'bert.cls.predictions.decoder.weight']
02/25/2021 10:09:24 - INFO - __main__ -   ***** Recover model: ./pretrained_model/non_cross/pytorch_model.bin *****
02/25/2021 10:09:31 - INFO - pytorch_pretrained_bert.model -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./output_model/base_noncross_mimic_2/.pretrained_model_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
02/25/2021 10:09:31 - INFO - pytorch_pretrained_bert.model -   extracting archive file ./output_model/base_noncross_mimic_2/.pretrained_model_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp6slsqy0v
02/25/2021 10:09:35 - INFO - pytorch_pretrained_bert.model -   Model config {
  "_name_or_path": "/home/hg_lee/cxr-bert/output/Base_sc_baseline/20210203_003450/7",
  "architectures": [
    "CXRBERT"
  ],
  "attention_probs_dropout_prob": 0.1,
  "fp32_embedding": false,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label_smoothing": null,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "relax_projection": 0,
  "task_idx": 3,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

02/25/2021 10:09:41 - INFO - pytorch_pretrained_bert.model -   Weights of BertForPreTrainingLossMask not initialized from pretrained model: ['bert.txt_embeddings.word_embeddings.weight', 'bert.txt_embeddings.position_embeddings.weight', 'bert.txt_embeddings.token_type_embeddings.weight', 'bert.txt_embeddings.LayerNorm.weight', 'bert.txt_embeddings.LayerNorm.bias', 'bert.img_embeddings.img_embeddings.weight', 'bert.img_embeddings.img_embeddings.bias', 'bert.img_embeddings.position_embeddings.weight', 'bert.img_embeddings.token_type_embeddings.weight', 'bert.img_embeddings.word_embeddings.weight', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias', 'bert.img_encoder.model.0.weight', 'bert.img_encoder.model.1.weight', 'bert.img_encoder.model.1.bias', 'bert.img_encoder.model.1.running_mean', 'bert.img_encoder.model.1.running_var', 'bert.img_encoder.model.4.0.conv1.weight', 'bert.img_encoder.model.4.0.bn1.weight', 'bert.img_encoder.model.4.0.bn1.bias', 'bert.img_encoder.model.4.0.bn1.running_mean', 'bert.img_encoder.model.4.0.bn1.running_var', 'bert.img_encoder.model.4.0.conv2.weight', 'bert.img_encoder.model.4.0.bn2.weight', 'bert.img_encoder.model.4.0.bn2.bias', 'bert.img_encoder.model.4.0.bn2.running_mean', 'bert.img_encoder.model.4.0.bn2.running_var', 'bert.img_encoder.model.4.0.conv3.weight', 'bert.img_encoder.model.4.0.bn3.weight', 'bert.img_encoder.model.4.0.bn3.bias', 'bert.img_encoder.model.4.0.bn3.running_mean', 'bert.img_encoder.model.4.0.bn3.running_var', 'bert.img_encoder.model.4.0.downsample.0.weight', 'bert.img_encoder.model.4.0.downsample.1.weight', 'bert.img_encoder.model.4.0.downsample.1.bias', 'bert.img_encoder.model.4.0.downsample.1.running_mean', 'bert.img_encoder.model.4.0.downsample.1.running_var', 'bert.img_encoder.model.4.1.conv1.weight', 'bert.img_encoder.model.4.1.bn1.weight', 'bert.img_encoder.model.4.1.bn1.bias', 'bert.img_encoder.model.4.1.bn1.running_mean', 'bert.img_encoder.model.4.1.bn1.running_var', 'bert.img_encoder.model.4.1.conv2.weight', 'bert.img_encoder.model.4.1.bn2.weight', 'bert.img_encoder.model.4.1.bn2.bias', 'bert.img_encoder.model.4.1.bn2.running_mean', 'bert.img_encoder.model.4.1.bn2.running_var', 'bert.img_encoder.model.4.1.conv3.weight', 'bert.img_encoder.model.4.1.bn3.weight', 'bert.img_encoder.model.4.1.bn3.bias', 'bert.img_encoder.model.4.1.bn3.running_mean', 'bert.img_encoder.model.4.1.bn3.running_var', 'bert.img_encoder.model.4.2.conv1.weight', 'bert.img_encoder.model.4.2.bn1.weight', 'bert.img_encoder.model.4.2.bn1.bias', 'bert.img_encoder.model.4.2.bn1.running_mean', 'bert.img_encoder.model.4.2.bn1.running_var', 'bert.img_encoder.model.4.2.conv2.weight', 'bert.img_encoder.model.4.2.bn2.weight', 'bert.img_encoder.model.4.2.bn2.bias', 'bert.img_encoder.model.4.2.bn2.running_mean', 'bert.img_encoder.model.4.2.bn2.running_var', 'bert.img_encoder.model.4.2.conv3.weight', 'bert.img_encoder.model.4.2.bn3.weight', 'bert.img_encoder.model.4.2.bn3.bias', 'bert.img_encoder.model.4.2.bn3.running_mean', 'bert.img_encoder.model.4.2.bn3.running_var', 'bert.img_encoder.model.5.0.conv1.weight', 'bert.img_encoder.model.5.0.bn1.weight', 'bert.img_encoder.model.5.0.bn1.bias', 'bert.img_encoder.model.5.0.bn1.running_mean', 'bert.img_encoder.model.5.0.bn1.running_var', 'bert.img_encoder.model.5.0.conv2.weight', 'bert.img_encoder.model.5.0.bn2.weight', 'bert.img_encoder.model.5.0.bn2.bias', 'bert.img_encoder.model.5.0.bn2.running_mean', 'bert.img_encoder.model.5.0.bn2.running_var', 'bert.img_encoder.model.5.0.conv3.weight', 'bert.img_encoder.model.5.0.bn3.weight', 'bert.img_encoder.model.5.0.bn3.bias', 'bert.img_encoder.model.5.0.bn3.running_mean', 'bert.img_encoder.model.5.0.bn3.running_var', 'bert.img_encoder.model.5.0.downsample.0.weight', 'bert.img_encoder.model.5.0.downsample.1.weight', 'bert.img_encoder.model.5.0.downsample.1.bias', 'bert.img_encoder.model.5.0.downsample.1.running_mean', 'bert.img_encoder.model.5.0.downsample.1.running_var', 'bert.img_encoder.model.5.1.conv1.weight', 'bert.img_encoder.model.5.1.bn1.weight', 'bert.img_encoder.model.5.1.bn1.bias', 'bert.img_encoder.model.5.1.bn1.running_mean', 'bert.img_encoder.model.5.1.bn1.running_var', 'bert.img_encoder.model.5.1.conv2.weight', 'bert.img_encoder.model.5.1.bn2.weight', 'bert.img_encoder.model.5.1.bn2.bias', 'bert.img_encoder.model.5.1.bn2.running_mean', 'bert.img_encoder.model.5.1.bn2.running_var', 'bert.img_encoder.model.5.1.conv3.weight', 'bert.img_encoder.model.5.1.bn3.weight', 'bert.img_encoder.model.5.1.bn3.bias', 'bert.img_encoder.model.5.1.bn3.running_mean', 'bert.img_encoder.model.5.1.bn3.running_var', 'bert.img_encoder.model.5.2.conv1.weight', 'bert.img_encoder.model.5.2.bn1.weight', 'bert.img_encoder.model.5.2.bn1.bias', 'bert.img_encoder.model.5.2.bn1.running_mean', 'bert.img_encoder.model.5.2.bn1.running_var', 'bert.img_encoder.model.5.2.conv2.weight', 'bert.img_encoder.model.5.2.bn2.weight', 'bert.img_encoder.model.5.2.bn2.bias', 'bert.img_encoder.model.5.2.bn2.running_mean', 'bert.img_encoder.model.5.2.bn2.running_var', 'bert.img_encoder.model.5.2.conv3.weight', 'bert.img_encoder.model.5.2.bn3.weight', 'bert.img_encoder.model.5.2.bn3.bias', 'bert.img_encoder.model.5.2.bn3.running_mean', 'bert.img_encoder.model.5.2.bn3.running_var', 'bert.img_encoder.model.5.3.conv1.weight', 'bert.img_encoder.model.5.3.bn1.weight', 'bert.img_encoder.model.5.3.bn1.bias', 'bert.img_encoder.model.5.3.bn1.running_mean', 'bert.img_encoder.model.5.3.bn1.running_var', 'bert.img_encoder.model.5.3.conv2.weight', 'bert.img_encoder.model.5.3.bn2.weight', 'bert.img_encoder.model.5.3.bn2.bias', 'bert.img_encoder.model.5.3.bn2.running_mean', 'bert.img_encoder.model.5.3.bn2.running_var', 'bert.img_encoder.model.5.3.conv3.weight', 'bert.img_encoder.model.5.3.bn3.weight', 'bert.img_encoder.model.5.3.bn3.bias', 'bert.img_encoder.model.5.3.bn3.running_mean', 'bert.img_encoder.model.5.3.bn3.running_var', 'bert.img_encoder.model.6.0.conv1.weight', 'bert.img_encoder.model.6.0.bn1.weight', 'bert.img_encoder.model.6.0.bn1.bias', 'bert.img_encoder.model.6.0.bn1.running_mean', 'bert.img_encoder.model.6.0.bn1.running_var', 'bert.img_encoder.model.6.0.conv2.weight', 'bert.img_encoder.model.6.0.bn2.weight', 'bert.img_encoder.model.6.0.bn2.bias', 'bert.img_encoder.model.6.0.bn2.running_mean', 'bert.img_encoder.model.6.0.bn2.running_var', 'bert.img_encoder.model.6.0.conv3.weight', 'bert.img_encoder.model.6.0.bn3.weight', 'bert.img_encoder.model.6.0.bn3.bias', 'bert.img_encoder.model.6.0.bn3.running_mean', 'bert.img_encoder.model.6.0.bn3.running_var', 'bert.img_encoder.model.6.0.downsample.0.weight', 'bert.img_encoder.model.6.0.downsample.1.weight', 'bert.img_encoder.model.6.0.downsample.1.bias', 'bert.img_encoder.model.6.0.downsample.1.running_mean', 'bert.img_encoder.model.6.0.downsample.1.running_var', 'bert.img_encoder.model.6.1.conv1.weight', 'bert.img_encoder.model.6.1.bn1.weight', 'bert.img_encoder.model.6.1.bn1.bias', 'bert.img_encoder.model.6.1.bn1.running_mean', 'bert.img_encoder.model.6.1.bn1.running_var', 'bert.img_encoder.model.6.1.conv2.weight', 'bert.img_encoder.model.6.1.bn2.weight', 'bert.img_encoder.model.6.1.bn2.bias', 'bert.img_encoder.model.6.1.bn2.running_mean', 'bert.img_encoder.model.6.1.bn2.running_var', 'bert.img_encoder.model.6.1.conv3.weight', 'bert.img_encoder.model.6.1.bn3.weight', 'bert.img_encoder.model.6.1.bn3.bias', 'bert.img_encoder.model.6.1.bn3.running_mean', 'bert.img_encoder.model.6.1.bn3.running_var', 'bert.img_encoder.model.6.2.conv1.weight', 'bert.img_encoder.model.6.2.bn1.weight', 'bert.img_encoder.model.6.2.bn1.bias', 'bert.img_encoder.model.6.2.bn1.running_mean', 'bert.img_encoder.model.6.2.bn1.running_var', 'bert.img_encoder.model.6.2.conv2.weight', 'bert.img_encoder.model.6.2.bn2.weight', 'bert.img_encoder.model.6.2.bn2.bias', 'bert.img_encoder.model.6.2.bn2.running_mean', 'bert.img_encoder.model.6.2.bn2.running_var', 'bert.img_encoder.model.6.2.conv3.weight', 'bert.img_encoder.model.6.2.bn3.weight', 'bert.img_encoder.model.6.2.bn3.bias', 'bert.img_encoder.model.6.2.bn3.running_mean', 'bert.img_encoder.model.6.2.bn3.running_var', 'bert.img_encoder.model.6.3.conv1.weight', 'bert.img_encoder.model.6.3.bn1.weight', 'bert.img_encoder.model.6.3.bn1.bias', 'bert.img_encoder.model.6.3.bn1.running_mean', 'bert.img_encoder.model.6.3.bn1.running_var', 'bert.img_encoder.model.6.3.conv2.weight', 'bert.img_encoder.model.6.3.bn2.weight', 'bert.img_encoder.model.6.3.bn2.bias', 'bert.img_encoder.model.6.3.bn2.running_mean', 'bert.img_encoder.model.6.3.bn2.running_var', 'bert.img_encoder.model.6.3.conv3.weight', 'bert.img_encoder.model.6.3.bn3.weight', 'bert.img_encoder.model.6.3.bn3.bias', 'bert.img_encoder.model.6.3.bn3.running_mean', 'bert.img_encoder.model.6.3.bn3.running_var', 'bert.img_encoder.model.6.4.conv1.weight', 'bert.img_encoder.model.6.4.bn1.weight', 'bert.img_encoder.model.6.4.bn1.bias', 'bert.img_encoder.model.6.4.bn1.running_mean', 'bert.img_encoder.model.6.4.bn1.running_var', 'bert.img_encoder.model.6.4.conv2.weight', 'bert.img_encoder.model.6.4.bn2.weight', 'bert.img_encoder.model.6.4.bn2.bias', 'bert.img_encoder.model.6.4.bn2.running_mean', 'bert.img_encoder.model.6.4.bn2.running_var', 'bert.img_encoder.model.6.4.conv3.weight', 'bert.img_encoder.model.6.4.bn3.weight', 'bert.img_encoder.model.6.4.bn3.bias', 'bert.img_encoder.model.6.4.bn3.running_mean', 'bert.img_encoder.model.6.4.bn3.running_var', 'bert.img_encoder.model.6.5.conv1.weight', 'bert.img_encoder.model.6.5.bn1.weight', 'bert.img_encoder.model.6.5.bn1.bias', 'bert.img_encoder.model.6.5.bn1.running_mean', 'bert.img_encoder.model.6.5.bn1.running_var', 'bert.img_encoder.model.6.5.conv2.weight', 'bert.img_encoder.model.6.5.bn2.weight', 'bert.img_encoder.model.6.5.bn2.bias', 'bert.img_encoder.model.6.5.bn2.running_mean', 'bert.img_encoder.model.6.5.bn2.running_var', 'bert.img_encoder.model.6.5.conv3.weight', 'bert.img_encoder.model.6.5.bn3.weight', 'bert.img_encoder.model.6.5.bn3.bias', 'bert.img_encoder.model.6.5.bn3.running_mean', 'bert.img_encoder.model.6.5.bn3.running_var', 'bert.img_encoder.model.7.0.conv1.weight', 'bert.img_encoder.model.7.0.bn1.weight', 'bert.img_encoder.model.7.0.bn1.bias', 'bert.img_encoder.model.7.0.bn1.running_mean', 'bert.img_encoder.model.7.0.bn1.running_var', 'bert.img_encoder.model.7.0.conv2.weight', 'bert.img_encoder.model.7.0.bn2.weight', 'bert.img_encoder.model.7.0.bn2.bias', 'bert.img_encoder.model.7.0.bn2.running_mean', 'bert.img_encoder.model.7.0.bn2.running_var', 'bert.img_encoder.model.7.0.conv3.weight', 'bert.img_encoder.model.7.0.bn3.weight', 'bert.img_encoder.model.7.0.bn3.bias', 'bert.img_encoder.model.7.0.bn3.running_mean', 'bert.img_encoder.model.7.0.bn3.running_var', 'bert.img_encoder.model.7.0.downsample.0.weight', 'bert.img_encoder.model.7.0.downsample.1.weight', 'bert.img_encoder.model.7.0.downsample.1.bias', 'bert.img_encoder.model.7.0.downsample.1.running_mean', 'bert.img_encoder.model.7.0.downsample.1.running_var', 'bert.img_encoder.model.7.1.conv1.weight', 'bert.img_encoder.model.7.1.bn1.weight', 'bert.img_encoder.model.7.1.bn1.bias', 'bert.img_encoder.model.7.1.bn1.running_mean', 'bert.img_encoder.model.7.1.bn1.running_var', 'bert.img_encoder.model.7.1.conv2.weight', 'bert.img_encoder.model.7.1.bn2.weight', 'bert.img_encoder.model.7.1.bn2.bias', 'bert.img_encoder.model.7.1.bn2.running_mean', 'bert.img_encoder.model.7.1.bn2.running_var', 'bert.img_encoder.model.7.1.conv3.weight', 'bert.img_encoder.model.7.1.bn3.weight', 'bert.img_encoder.model.7.1.bn3.bias', 'bert.img_encoder.model.7.1.bn3.running_mean', 'bert.img_encoder.model.7.1.bn3.running_var', 'bert.img_encoder.model.7.2.conv1.weight', 'bert.img_encoder.model.7.2.bn1.weight', 'bert.img_encoder.model.7.2.bn1.bias', 'bert.img_encoder.model.7.2.bn1.running_mean', 'bert.img_encoder.model.7.2.bn1.running_var', 'bert.img_encoder.model.7.2.conv2.weight', 'bert.img_encoder.model.7.2.bn2.weight', 'bert.img_encoder.model.7.2.bn2.bias', 'bert.img_encoder.model.7.2.bn2.running_mean', 'bert.img_encoder.model.7.2.bn2.running_var', 'bert.img_encoder.model.7.2.conv3.weight', 'bert.img_encoder.model.7.2.bn3.weight', 'bert.img_encoder.model.7.2.bn3.bias', 'bert.img_encoder.model.7.2.bn3.running_mean', 'bert.img_encoder.model.7.2.bn3.running_var', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'bert.cls.predictions.bias', 'bert.cls.predictions.transform.dense.weight', 'bert.cls.predictions.transform.dense.bias', 'bert.cls.predictions.transform.LayerNorm.weight', 'bert.cls.predictions.transform.LayerNorm.bias', 'bert.cls.predictions.decoder.weight']
02/25/2021 10:09:41 - INFO - __main__ -   ***** CUDA.empty_cache() *****
02/25/2021 10:09:41 - INFO - __main__ -   ***** Running training *****
