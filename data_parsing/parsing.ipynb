{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "import math\n",
    "import random\n",
    "import tqdm as tqdm\n",
    "import albumentations\n",
    "import collections\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of jpg files 313665\n",
      "# of free_text files 227835\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "jpg = glob(\"/home/ubuntu/mimic_jpg/physionet.org/files/mimic-cxr-jpg/2.0.0/files/*/*/*/*.jpg\")\n",
    "free_text = glob(\"/home/ubuntu/mimic_jpg/files/*/*/*.txt\")\n",
    "\n",
    "jpg = pd.DataFrame({\"dir\" : jpg})\n",
    "free_text = pd.DataFrame({\"dir\" : free_text})\n",
    "\n",
    "print(\"# of jpg files\", len(jpg))\n",
    "print(\"# of free_text files\",len(free_text))\n",
    "#path matching\n",
    "jpg[\"study\"] = jpg[\"dir\"].str.split(pat = \"/\", expand = True)[11]\n",
    "jpg[\"num_of_study\"] = pd.to_numeric(jpg.study.str.slice(start=1))\n",
    "\n",
    "free_text[\"study\"] = free_text[\"dir\"].str.split(pat = \"/\", expand = True)[7]\n",
    "a = free_text[\"study\"].str.split(pat = \".\", expand = True)\n",
    "free_text[\"num_of_study\"] = pd.to_numeric(a[0].str.slice(start=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/mimic_jpg/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11/p11573679/s58235663/1a671a62-0a32dfc6-5f85029c-81c3922e-3f5a2c27.jpg',\n",
       " '/home/ubuntu/mimic_jpg/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p16/p16175671/s56724958/92c2d3f2-81af6356-c4ba9b42-1c9636b9-ae69d8b3.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_txt_2 = glob(\"/home/ubuntu/check_txt/2manual_parsing/*.txt\")\n",
    "chk_txt_24 = glob(\"/home/ubuntu/check_txt/24manual_parsing/*.txt\")\n",
    "\n",
    "chk_txt_2 = pd.DataFrame({\"dir\" : chk_txt_2})\n",
    "chk_txt_24 = pd.DataFrame({\"dir\" : chk_txt_24})\n",
    "\n",
    "chk_txt_24[\"study\"] = chk_txt_24[\"dir\"].str.split(pat = \"/\", expand = True)[5]\n",
    "re_split = chk_txt_24[\"study\"].str.split(pat = \".\", expand = True)\n",
    "chk_txt_24[\"study number\"] = pd.to_numeric(re_split[0].str.slice(start=1))\n",
    "\n",
    "# chk_txt_path = jpg[jpg.num_of_study.isin(chk_txt_24['study number'])]\n",
    "# chk_txt_path_list = chk_txt_path.dir.tolist() \n",
    "\n",
    "# chk_txt_path_list2\n",
    "\n",
    "chk_txt_2[\"study\"] = chk_txt_2[\"dir\"].str.split(pat = \"/\", expand = True)[5]\n",
    "re_split2 = chk_txt_2[\"study\"].str.split(pat = \".\", expand = True)\n",
    "chk_txt_2[\"study number\"] = pd.to_numeric(re_split2[0].str.slice(start=1))\n",
    "\n",
    "chk_txt_path2 = jpg[jpg.num_of_study.isin(chk_txt_2['study number'])]\n",
    "chk_txt_path_list2 = chk_txt_path2.dir.tolist() \n",
    "\n",
    "chk_txt_path_list2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s None\n"
     ]
    }
   ],
   "source": [
    "def section_text(text):\n",
    "    \"\"\"Splits text into sections.\n",
    "\n",
    "    Assumes text is in a radiology report format, e.g.:\n",
    "\n",
    "        COMPARISON:  Chest radiograph dated XYZ.\n",
    "\n",
    "        IMPRESSION:  ABC...\n",
    "\n",
    "    Given text like this, it will output text from each section, \n",
    "    where the section type is determined by the all caps header.\n",
    "\n",
    "    Returns a three element tuple:\n",
    "        sections - list containing the text of each section\n",
    "        section_names - a normalized version of the section name\n",
    "        section_idx - list of start indices of the text in the section\n",
    "    \"\"\"\n",
    "    p_section = re.compile(\n",
    "        r'\\n ([A-Z ()/,-]+):\\s', re.DOTALL)\n",
    "    \n",
    "    sections = list()\n",
    "    section_names = list()\n",
    "    section_idx = list()\n",
    "\n",
    "    idx = 0\n",
    "    s = p_section.search(text, idx)\n",
    "    print(\"s\",s)\n",
    "    input()\n",
    "    \n",
    "    if s:\n",
    "        sections.append(text[0:s.start(1)])\n",
    "        section_names.append('preamble')\n",
    "        section_idx.append(0)\n",
    "\n",
    "        while s:\n",
    "            current_section = s.group(1).lower()\n",
    "            # get the start of the text for this section\n",
    "            idx_start = s.end()\n",
    "            # skip past the first newline to avoid some bad parses\n",
    "            idx_skip = text[idx_start:].find('\\n')\n",
    "            if idx_skip == -1:\n",
    "                idx_skip = 0\n",
    "\n",
    "            s = p_section.search(text, idx_start + idx_skip)\n",
    "\n",
    "            if s is None:\n",
    "                idx_end = len(text)\n",
    "            else:\n",
    "                idx_end = s.start()\n",
    "\n",
    "            sections.append(text[idx_start:idx_end])\n",
    "            section_names.append(current_section)\n",
    "            section_idx.append(idx_start)\n",
    "\n",
    "    else:\n",
    "        sections.append(text)\n",
    "        section_names.append('full report')\n",
    "        section_idx.append(0)\n",
    "\n",
    "    section_names = normalize_section_names(section_names)\n",
    "\n",
    "    # remove empty sections\n",
    "    # this handles when the report starts with a finding-like statement\n",
    "    #  .. but this statement is not a section, more like a report title\n",
    "    #  e.g. p10/p10103318/s57408307\n",
    "    #    CHEST, PA LATERAL:\n",
    "    #\n",
    "    #    INDICATION:   This is the actual section ....\n",
    "    # it also helps when there are multiple findings sections\n",
    "    # usually one is empty\n",
    "    for i in reversed(range(len(section_names))):\n",
    "        if section_names[i] in ('impression', 'findings'):\n",
    "            if sections[i].strip() == '':\n",
    "                sections.pop(i)\n",
    "                section_names.pop(i)\n",
    "                section_idx.pop(i)\n",
    "\n",
    "    if ('impression' not in section_names) & ('findings' not in section_names):\n",
    "        # create a new section for the final paragraph\n",
    "        if '\\n \\n' in sections[-1]:\n",
    "            sections.append('\\n \\n'.join(sections[-1].split('\\n \\n')[1:]))\n",
    "            sections[-2] = sections[-2].split('\\n \\n')[0]\n",
    "            section_names.append('last_paragraph')\n",
    "            section_idx.append(section_idx[-1] + len(sections[-2]))\n",
    "\n",
    "    return sections, section_names, section_idx\n",
    "\n",
    "def normalize_section_names(section_names):\n",
    "    # first, lower case all\n",
    "    section_names = [s.lower().strip() for s in section_names]\n",
    "\n",
    "    frequent_sections = {\n",
    "        \"preamble\": \"preamble\",  # 227885\n",
    "        \"impression\": \"impression\",  # 187759\n",
    "        \"comparison\": \"comparison\",  # 154647\n",
    "        \"indication\": \"indication\",  # 153730\n",
    "        \"findings\": \"findings\",  # 149842\n",
    "        \"examination\": \"examination\",  # 94094\n",
    "        \"technique\": \"technique\",  # 81402\n",
    "        \"history\": \"history\",  # 45624\n",
    "        \"comparisons\": \"comparison\",  # 8686\n",
    "        \"clinical history\": \"history\",  # 7121\n",
    "        \"reason for examination\": \"indication\",  # 5845\n",
    "        \"notification\": \"notification\",  # 5749\n",
    "        \"reason for exam\": \"indication\",  # 4430\n",
    "        \"clinical information\": \"history\",  # 4024\n",
    "        \"exam\": \"examination\",  # 3907\n",
    "        \"clinical indication\": \"indication\",  # 1945\n",
    "        \"conclusion\": \"impression\",  # 1802\n",
    "        \"chest, two views\": \"findings\",  # 1735\n",
    "        \"recommendation(s)\": \"recommendations\",  # 1700\n",
    "        \"type of examination\": \"examination\",  # 1678\n",
    "        \"reference exam\": \"comparison\",  # 347\n",
    "        \"patient history\": \"history\",  # 251\n",
    "        \"addendum\": \"addendum\",  # 183\n",
    "        \"comparison exam\": \"comparison\",  # 163\n",
    "        \"date\": \"date\",  # 108\n",
    "        \"comment\": \"comment\",  # 88\n",
    "        \"findings and impression\": \"impression\",  # 87\n",
    "        \"wet read\": \"wet read\",  # 83\n",
    "        \"comparison film\": \"comparison\",  # 79\n",
    "        \"recommendations\": \"recommendations\",  # 72\n",
    "        \"findings/impression\": \"impression\",  # 47\n",
    "        \"pfi\": \"history\",\n",
    "        'recommendation': 'recommendations',\n",
    "        'wetread': 'wet read',\n",
    "        'ndication': 'impression',  # 1\n",
    "        'impresson': 'impression',  # 2\n",
    "        'imprression': 'impression',  # 1\n",
    "        'imoression': 'impression',  # 1\n",
    "        'impressoin': 'impression',  # 1\n",
    "        'imprssion': 'impression',  # 1\n",
    "        'impresion': 'impression',  # 1\n",
    "        'imperssion': 'impression',  # 1\n",
    "        'mpression': 'impression',  # 1\n",
    "        'impession': 'impression',  # 3\n",
    "        'findings/ impression': 'impression',  # ,1\n",
    "        'finding': 'findings',  # ,8\n",
    "        'findins': 'findings',\n",
    "        'findindgs': 'findings',  # ,1\n",
    "        'findgings': 'findings',  # ,1\n",
    "        'findngs': 'findings',  # ,1\n",
    "        'findnings': 'findings',  # ,1\n",
    "        'finidngs': 'findings',  # ,2\n",
    "        'idication': 'indication',  # ,1\n",
    "        'reference findings': 'findings',  # ,1\n",
    "        'comparision': 'comparison',  # ,2\n",
    "        'comparsion': 'comparison',  # ,1\n",
    "        'comparrison': 'comparison',  # ,1\n",
    "        'comparisions': 'comparison'  # ,1\n",
    "    }\n",
    "\n",
    "    p_findings = [\n",
    "        'chest',\n",
    "        'portable',\n",
    "        'pa and lateral',\n",
    "        'lateral and pa',\n",
    "        'ap and lateral',\n",
    "        'lateral and ap',\n",
    "        'frontal and',\n",
    "        'two views',\n",
    "        'frontal view',\n",
    "        'pa view',\n",
    "        'ap view',\n",
    "        'one view',\n",
    "        'lateral view',\n",
    "        'bone window',\n",
    "        'frontal upright',\n",
    "        'frontal semi-upright',\n",
    "        'ribs',\n",
    "        'pa and lat'\n",
    "    ]\n",
    "    p_findings = re.compile('({})'.format('|'.join(p_findings)))\n",
    "\n",
    "    main_sections = [\n",
    "        'impression', 'findings', 'history', 'comparison',\n",
    "        'addendum'\n",
    "    ]\n",
    "    for i, s in enumerate(section_names):\n",
    "        if s in frequent_sections:\n",
    "            section_names[i] = frequent_sections[s]\n",
    "            continue\n",
    "\n",
    "        main_flag = False\n",
    "        for m in main_sections:\n",
    "            if m in s:\n",
    "                section_names[i] = m\n",
    "                main_flag = True\n",
    "                break\n",
    "        if main_flag:\n",
    "            continue\n",
    "\n",
    "        m = p_findings.search(s)\n",
    "        if m is not None:\n",
    "            section_names[i] = 'findings'\n",
    "\n",
    "        # if it looks like it is describing the entire study\n",
    "        # it's equivalent to findings\n",
    "        # group similar phrasings for impression\n",
    "\n",
    "    return section_names\n",
    "\n",
    "\n",
    "\n",
    "sections, section_names, section_idx = section_text(chk_txt_path_list2[0])\n",
    "print(sections)\n",
    "print(section_names)\n",
    "print(section_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_mimic_cxr_rules():\n",
    "    custom_section_names = {\n",
    "        's50913680': 'recommendations',  # files/p11/p11851243/s50913680.txt\n",
    "        's59363654': 'examination',  # files/p12/p12128253/s59363654.txt\n",
    "        's59279892': 'technique',  # files/p13/p13150370/s59279892.txt\n",
    "        's59768032': 'recommendations',  # files/p13/p13249077/s59768032.txt\n",
    "        's57936451': 'indication',  # files/p14/p14325424/s57936451.txt\n",
    "        's50058765': 'indication',  # files/p14/p14731346/s50058765.txt\n",
    "        's53356173': 'examination',  # files/p15/p15898350/s53356173.txt\n",
    "        's53202765': 'technique',  # files/p16/p16076182/s53202765.txt\n",
    "        's50808053': 'technique',  # files/p16/p16631485/s50808053.txt\n",
    "        's51966317': 'indication',  # files/p10/p10817099/s51966317.txt\n",
    "        's50743547': 'examination',  # files/p11/p11388341/s50743547.txt\n",
    "        's56451190': 'note',  # files/p11/p11842879/s56451190.txt\n",
    "        's59067458': 'recommendations',  # files/p11/p11984647/s59067458.txt\n",
    "        's59215320': 'examination',  # files/p12/p12408912/s59215320.txt\n",
    "        's55124749': 'indication',  # files/p12/p12428492/s55124749.txt\n",
    "        's54365831': 'indication',  # files/p13/p13876470/s54365831.txt\n",
    "        's59087630': 'recommendations',  # files/p14/p14267880/s59087630.txt\n",
    "        's58157373': 'recommendations',  # files/p15/p15032392/s58157373.txt\n",
    "        's56482935': 'recommendations',  # files/p15/p15388421/s56482935.txt\n",
    "        's58375018': 'recommendations',  # files/p15/p15505556/s58375018.txt\n",
    "        's54654948': 'indication',  # files/p17/p17090359/s54654948.txt\n",
    "        's55157853': 'examination',  # files/p18/p18975498/s55157853.txt\n",
    "        's51491012': 'history',  # files/p19/p19314266/s51491012.txt\n",
    "\n",
    "    }\n",
    "\n",
    "    custom_indices = {\n",
    "        's50525523': [201, 349],  # files/p10/p10602608/s50525523.txt\n",
    "        's57564132': [233, 554],  # files/p10/p10637168/s57564132.txt\n",
    "        's59982525': [313, 717],  # files/p11/p11989982/s59982525.txt\n",
    "        's53488209': [149, 475],  # files/p12/p12458657/s53488209.txt\n",
    "        's54875119': [234, 988],  # files/p13/p13687044/s54875119.txt\n",
    "        's50196495': [59, 399],  # files/p13/p13894879/s50196495.txt\n",
    "        's56579911': [59, 218],  # files/p15/p15394326/s56579911.txt\n",
    "        's52648681': [292, 631],  # files/p15/p15666238/s52648681.txt\n",
    "        's59889364': [172, 453],  # files/p15/p15835529/s59889364.txt\n",
    "        's53514462': [73, 377],  # files/p16/p16297706/s53514462.txt\n",
    "        's59505494': [59, 450],  # files/p16/p16730991/s59505494.txt\n",
    "        's53182247': [59, 412],  # files/p16/p16770442/s53182247.txt\n",
    "        's51410602': [47, 320],  # files/p17/p17069955/s51410602.txt\n",
    "        's56412866': [522, 822],  # files/p17/p17612000/s56412866.txt\n",
    "        's54986978': [59, 306],  # files/p17/p17912487/s54986978.txt\n",
    "        's59003148': [262, 505],  # files/p17/p17916384/s59003148.txt\n",
    "        's57150433': [61, 394],  # files/p18/p18335791/s57150433.txt\n",
    "        's56760320': [219, 457],  # files/p18/p18418794/s56760320.txt\n",
    "        's59562049': [158, 348],  # files/p18/p18502016/s59562049.txt\n",
    "        's52674888': [145, 296],  # files/p19/p19381919/s52674888.txt\n",
    "        's55258338': [192, 568],  # files/p13/p13719117/s55258338.txt\n",
    "        's59330497': [140, 655],  # files/p15/p15479218/s59330497.txt\n",
    "        's52119491': [179, 454],  # files/p17/p17959278/s52119491.txt\n",
    "        # below have no findings at all in the entire report\n",
    "        's58235663': [0, 0],  # files/p11/p11573679/s58235663.txt\n",
    "        's50798377': [0, 0],  # files/p12/p12632853/s50798377.txt\n",
    "        's54168089': [0, 0],  # files/p14/p14463099/s54168089.txt\n",
    "        's53071062': [0, 0],  # files/p15/p15774521/s53071062.txt\n",
    "        's56724958': [0, 0],  # files/p16/p16175671/s56724958.txt\n",
    "        's54231141': [0, 0],  # files/p16/p16312859/s54231141.txt\n",
    "        's53607029': [0, 0],  # files/p17/p17603668/s53607029.txt\n",
    "        's52035334': [0, 0],  # files/p19/p19349312/s52035334.txt\n",
    "    }\n",
    "\n",
    "    return custom_section_names, custom_indices\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
